- Microservices meaning breaking down big code base into independnet deployable units based on functionlaity/domain
	-> each of these service can communicate with light weight protocols like http
advantages:
- helps in productiveness of devleopers/ new dev joining can pick things quickly
- deloyment can be done quicker with time
- auttoscaling can be done independently
- auto deployment automatically
- paralle devlopment can happen for a lot of functionlaities
- each service can be based on best possible language and D.B and other implementation techniques
- helps in implementing changes quiclky and less testing is needed
- imporoves fault tolerance , in case of monolith if app goes down all the application goes down but here we can have fault tolerance based on if that specific service is down or not
- improves hardware cost  -> only service whihc are high io we cna execute on that kind of hardware -> helping us to reduce hardware cost

Server side load balancing: Along with service instances (autoscalable) we have a load balancer
	client will call this and load blancer(like ELB in aws) calls the individual service making it two calls even for a single clal
-> this resulted in client side load balancing that uses service registration/discovery
-> each service will have list ips of service to call using eureka/service registry and client decided whihc one to go and hence reducing the call by one

Benefits of client side load balancing over server side
- improves performance as client directly calls the service and do not use server side load balancer

Examples of discovery server:
a. eureka
b. consul
c. zookepper by apache

- ribbon can do retrying also in case local cahced instance is actually down as max 120 second can be downtime for one instance of a service
	-> this retry will ensure that it goes to another instance of service and hence there is a chance that other is up
	-> if all instances are down then we need to return some default value using hystrix circuit breaker
- ribbon client load balancer helps in calculating the average times of response from each service and put in cache so that weighted algo can find whihc instance to call
	-> first time it will be rounbd robin then it keeps on creating average response time for each instance and later on uses this data to clacualte which instance to call

Bulkhead pattern:
divede thread pools among services and hence if one is slow number of thereads assigned for other services will not be impacted
- > hystric can implement circuit breaker pattern and bulkahead pattern both

circuit breaker:
when everything is going good curcuit is closed and service 1 is calling sergice 2
-> once service 2 gets timed out we keep on incremenitng the count of failueres -> s1 calls s2 failure count increases and s1 return default/cached value to its client
-> this will happen until threshold percent is reached -> once reached it opens the circuit and then all calls to s2 will blocked until sleep time is over
		-> it retruns vlaue from local cahce/default and until sleep time is over it keeps on returning default value

API gateway:
- acts as entry point for external clients, interservice communcation need not happen through it , that can happen directly
- since ip of services might change in cloud based application we need some one whohc can do reverse proxy
benefits:
- reverse proxy
- rate limiting, like how many services can be allowed for users in a given time
- throttling
- secturty features
- load balancing using reibbo and do routing based on eureka
- lets say we want to expose only few of services we can give the route rules to allow only thos service to clinet
- static content
- aggregator -> one request neededing multiple api calls
- hystrix circuit and bulkhead pattern
- loggin/tracing

Spring integration : 
This hleps in introducing logical connection bwetween clinet and server,
lets say we have one clinetn and one server connecting via soap service
	-> it is loosely coupled meaning change in one place do not affect other untill wsdl contraact is fllowed
	-> however if the communication method cahnges form soap to rest our code has to eb modified
Spring integration provides a commnon channel that hels us adpt and integrate with different third party integrations
	-> how it does is it creates in memory queue and our job in code will be to just create a serialzble class and call the method of integrator that puts the data ina  queue in memory,
	-> we can configure throught externilzied config(indepenednt of code) to setup adapter that takes data the queue and conevrt to usable format of thirsd party server.
Eg is spring cloud config
-> if there are different ways of brokers like kafka , rabbit mq
	-> this mechaniss is built on top of sprin integration
	-> we have to just provide the message and put in memory queue , configured adapter (eg one for rabbit, one for kafka, one for kinesis) picks it and convert to its desired output
	-> and send this message ot broker, this helps in server implementation may change but from client side no code change , only config changesare needed
----- This is how ESB also works it allows us to integrate between differnet technologies cliet/server connect together and any change in cleint and server wont affect each other
	-> as the conversion of format is taken care by ESB- >renterprise service bus
--Spring integration is example of EBS
- This allows to write a code in common way so that server can either be SOAP service, or rest service or Data base , in configuration we can decalaravive setup the server

Steps in Domain driven design
- First identify the business problem space
- Identitfy the domains and subdomanis
- within subdominas identify the aggregate object(whihc is root of that specfic functionaloty of subdomain) and entities(child items of agreegate)
- in monilith for each subdomain we have code for all aggregate and entities in same code base
- in microservice we will identify the spaces/sagas/business rules for each of these aggregates and keep them isolated
- each of these entitities and aggregates can interact using rest
- identify the busniess rules/saga for each agggregate and find the commands(methods to updat ethe aggreagate and its object) and queries

importnant points in DDD implementations:
- use embeded even for values in aggregator : eg amount -> do not [put directly in order aggreagate object instead use embedable and embeded -> loose coupling and flexibility
- use DTO for Rest api reuqest and use a sepearete business service to convert to DAO class
- as part of DDD once a aggreagate object is publichsed in DB we moight have to send event,
	so  for each object first find operations/commands(change the state), queries and events
	for each of oabove these create differnet service impls
- once aggreagate object is created in consructor we should register object as a message in a in memory event ,assign transationalListnere to these 
	-> if DB transation fails in service impl the vent will be ignored
- use messaging sreams using differnet channel for each even type
- tyoe s of service impls
	a. query service impl for entties and aggregator object , -> will have only filtering / querying of objects present in DB
	b. command service inpl : have methods related to things that change state of aggregator
	c. events : shud have transactionalListenre annotated methods calling indivusla cloud stream channels for sending events to rabbit/kafka brokers 
	-> aggreagtor object constructor shud register the evne and once transaction completes in memory transaction listenr can pick the aggreagate objec and send mesage to broker
- Class that populates the message recieved from message broker as part of listern events should transfor to another bean specific to that domain service
	-> this is called Anti corruption layer.
	in future if message instance variables are changed in prodcuer it do not affec the consumers bean

- maven by default support single parent dependencies using parent tag
- however we cna use dependencymangement tag to add new depenency versions and just add dependency in dependency tag -> using scope import and type as pom

Eureka 
Even though eureka goes down it is not single point of failure as by default each eureka client have locaal copy
- also using ribbon in case local cache is old and eureka is stil not up we can retry tp another instance
- if still it can go to fallback using fault tolearance
- eureka by default expects a cluster of instances working togehter in cloud
so we have to skip the self registry for each eureka instance-> in cloud on each AZs we can have its own local eureka instance for performance concerns
-> thse instance for high availability keeps trakc of registry from another one, thats why in case of single instance eureka we need to skip the slef registry

If we need to have a cluster of eureka server we can insert ip of one of the instance in another instance
-> this way they communicate with each other to fetch others registry and hence intrdouced high availability

In eureka client we need to add client dependency and then add eureka client service urls for each zone
	, if single instance is there put key as defaultZone
jobs of registry client::
a. register on startup
b. send heartbeat to server
c. fetches latest registry list from server to put in cache
d. Everytime one of the clinet instance is shutdown it send a call to server that i am getting down and hence eureka registry will be updated
- eureka server do not deregisters from its registry list on just one missing heat beat
	-> it do it after 3 consecutiry attemps in failed heat beat
	-> however on shutdown manually by server unless force kill , client send kill event and hence registry is removed from server
- when machine gets killed due to overuse then eureka cloient wont be able to send deregistration event and hence till 120 seconds there is a chance

Types of Calls bewtween eureka server and client:
a. GET call : list of all the registered API for the first time
b. GET delta: Betwen lat 30 seconds it provides registera api list
c. POST: Registration event at server startup from client
d. PUT: Heart beat call from cleint to server
e. DELETE: Once we shutdown the instance manually and gracefully it sends this so that server can deregister the instance from list:
 -> in case there is a force kill beacuse of service usage overload of eureka client
	then untill 3 failed heartbeat eureka server push the instance to evicttion list and after every 60 seconds a thread runs and kill these kinds of instances whihca re marked to be evicted
In case of force kill of eureka client -> eviction rule happens , in case of graceful shutdwon directly eureka server removes the ip from registry

@enableEurekaServer : This annotation creates a markup bean and instantiates it
-> there is a auto configure bean which is conditional ot be executed only if this amrkup bean is instantiated
- By default eureka server is both client and server , Client tries to register to another cluster of eureka(for high availability) -> in case of single instance it will give error
- > to skip this error we can to skip the flag of registration in eureka server whwn there is only one instance
- >if there are cluster of instances of eureka we can add this in list for each of the instances

Server part of eureka serve looks for registry details and heart beat from its client and provides the list of registry once another client asks for it

eureka self preservation mode of eureka server: In case a lot of heart beats are not reaching ., if it reaches more than 15 percent , 
 once if the flag is set to true (default vlaue) and in case 15 percent of total instances goes to eviction mode then it means there is ome netwrok issue
as on production this is not possible that 15 percent of instance is donw specially in cloud

-> so if the flag is true (default value) and eviction count goes more than 15 percent of total then it enter the self preservation mode and hence it do not kill any of the registry till some time beeing
- on prod this shud always be true in lcoal or dev we can make this as false so that we cna amke some space

While creating clustered peers of eureka we need to do following
- we need to make register to false for all three instance of eureka
- we need to maeke fetch registry as true for all three
- and for each one of them the service url for client to fetch registry data we shud set as other two instances

- By default even without ribbon dependency addition load balanced rest template uses it by defautl and uses round robin algo
- for custom algo we need to introduce the ribbon depenedency
@ loadBalacned annotation on resttemplate adds an interceptor that runs a logic and uses loadblacnedclient service to find the correct ip based on algo-
- internally uses loadbalancedclient instead of discovrey client to pass service name and get ip and port combination
- However in kubernetes we will get only the ip based on passing the service name and port is not provided by service discovery

So basic fundamental of riboon is to provide an interceptor on resttemplate/feign client level 
- which will gets exectued before each rest call to third party which are configured to eb enabled in ribbon config in application.proeprties
- we can set timeout, total retry timeout, retry count total, retry count total per instance etc, enable/disable ribbon based on service name
- to enable retry in ribbon load balancing intercepto we need to introduce spring-retry dependency -> in our case it was already present as we added spring cloud stream dependency

- Ribbon by default picks alls the list of ip for a service from eureka, 
	-> if we want to call a service that is not added to eureka we can set -> servicename.ribbon.eureka.enabled=false(default is true)
		and then provide list of ips to call the third party, basically for ribbon all the condig are based on service name
- Id we are setting up cluster of eureka each one of them have same extra copy, if we want to fetch from only one zone
	-> We need to confifure ZoneavaiableLoadBlancer- > implenentation of ILoadBalancer -> this class hav method to provide list of ips, based on eureka or non eureka
	-> We can customize the algo to do load balancing using implementaiton of IRule interface
	-> we cna create Ribbon client annotation and pass custom config based on service name
	-> eg one service need wighter other one different so we cna create config classes for each service and add @ribbonClient -> pass the name of service and its config class

- hystrix uses AOP that is based on reflection form java
- hystrix uses hystrixcommand proeprty to create proxy of class and hence it will call this wheneven an exception occurs.
- Whena  method in the same class calls another method whihc have hystrixCommand annotation it wont work as proxy wont be created and referred for the same class
-  we can set configproperties in application.properties for each circuit based on commandkey
- hystrix uses buckets to handle different slots of success/failure count -> if this was not the case after 1 hour whene there is so much success count percentage of failure will alwasy be less than threshold
	-> this bucket refreshes every 10 seconds and this can be configured , total bucket size is 10 and can be configured
- default propety of hystrix commands and properties can be set in one place in application.properties
	-> if we want to haev some different value form few of them we can overrdide them in application.proeprties
	- > hystrix.thread.commandkey.proeprty
		-> hystrix.property.comandKey.property=
- for proeprties we use commandkey as identifier and for threadpool proeprties(bulkhead pattern) we use threadpoolkey
- bulkhead pattern: instead of directly consuming threads of tomcat lets divide number of threads and create new custom threads to call the apis/DB
	-> to skip this we can use isolation.strategy s semaphore (default is thread meaning seperate thread)
	-> it will call using same thread and hence we wont be able to divide threads among services

Turbine:
It is used in conjunction with hystrix dashboard: 
	>  a hystrix dashboard can be used to read hystrix metrics using hystrix.stream actuaator of apis
-	> we create anew application with hystrix dashboard dependnecy
	-> we add actualator and allwo hystrix.stream actuator endpoint in services using circuit break modules
	-> we give this path in dashboard and we cna see metrics
- Turbine is likea  cluster that can help us see the hystrix metrics of all the services(configured)
	- > it picks the list from eureka by becomming eureak client
- hystrix fallback method gets called on any exfeption
	-> for ex db call then rest call , even though we want fallback only during rest api call
-> we can provide ignore list of excpetions
-> better to use feign client whihc integrates with eureka, ribbon, hystrix, sleuth , zipkin etc

- Spring cloud config is a way of externalizing the config
- Using this we can keep config of all the services at one place
- also at runtime we can modify the value and after calling refreshscope it will reflect on those server at runtime
- we can keep application.properties in config server for the proeprties whihc are common to all the service , also based on profile we na override it using application-dev.properties
- in config server we can keep service specific configuration in file using serviceappliationName.properteis and for profile based application-dev.properties and so on
- if no profile is appased first it picks application.ym and then the servicename.properties
- in case of profile first it picks apploication.properties then application-profilkename.proeprties and then service.properties and service-profile.propetteis and pass the json to config client
- -  We cna use git,sv,db ,file system to manage the config values

-  we need to remae the application.proeprties to bootstrap/properties and keep only application.name and cloud config client proeprties in client services
-> move everything else to config server common place using file name as serviceName-profileName.properties
- config client fetches latest properties from config server(whih is always updated) and puts in caceh for performance reasons
	-> if on rutoime it si added dynamically we need to call refresh actualtor endpoint -> add actualtor dependecny in config client and add web exposure include for refresh endpoint
@refreshScope provided a refrehs of properties only in that bean -> it is nothing but a new scope
	-> when we call actualtor refresh it just refreshed the properties but the bean whihc are singleton do not gets updated
	-> for these for each bean whihc is using config properties in clinet we need to add refreshscope

- In case there are multiple instances of config client doing actuator/refresh will do refresh proeprties only on those instances
-> so we can use a bus framework called spring cloud bus
	-> this uses rabbit mq stream by default
	-> once we allow /bus-refresh actuator endpoint and in config client provides rabbit mq details like host port etc
	-> if we call the bus refresh at any one instance it will put the message in a exchange of rabbit mq with name springcloudbus(default)
	-> all the other instances will be listned to this queu and the type of exchange will be fanout so all the queues will pick this message whihc are linked to springcloudbus
	-> hence the new config proeprty will be reflected to all the instances of config client service


=========event sourcing========
- In domain driven system each bounded context change notifies an envent to another bounded context, 
	- event source says we should store the list of events recieved on each changes in another system
	-> This can help in creating utility function in case of data courruption to create the whol aggreagate object by applying these events one by one
	-> each event will have command we cna execute this set of commands on data and that can give us latest state of aggregate object

CQRS -> Command query segregation System
 - Generally in DDD we will have different bounded context each having aggregrate objects
	-> each command is the event of updating the state of aggregate object
	-> each query is the view/query for state of these objects
-	We know that there will be a lot of read requests and also since we generally have data segregated in different tables/views -> joining will be need in querying
	-> this reduces the performacne of reading in application
- CQRS design patterns says  lets seggregate the command and query part into teo differentr application
	- > in each comamnd request we can update the data in D.B of command application and on transactional in memeory listerner we cna send message to broker
	-> this broker can be listened by Query application that have simple table that do not need joining,
	structure of table in read application can be based on how front end needs
	-> similiarly thes same event can be listedn by reportining tools, as in microservices if reporting aggregates data from differnetn application and join from them in memory
	->  it will be xtremelry slow- > so i the same event during command we can add a listener for reporting applicaiton 
	-> whihc will update the tables in their own format so that reposrting query becomes faster and no need to join tbales on read

- Also CQRS is also combined with event sourcing where we do not even keep data base in command application ->  we just send message to report and query applications
	-> both can act as event source and on read we can apply all the events in event soruce to get the latest state of aggregate obbject

Axon is a framework that supports CQRS and event sourcing
- > flow
- We seperate Command and Query applications 
- On command application from controller we create an event and we push the event to Axon queue(internally using rabbit/kafka)
	-> once we send the command , the axon will call the aggregate and look for @comandHandler annotated method of same command object type
	-> from there we can create aggreagate object and pass it to eventSourceHandker annotated method
	-> from there it calls event queue of Axon tool, Where it store the event on D.B like h2
- On query application
	-> aggregate object will be looking for event soruce from axon -> uses the same @eventSorucehandler annotation
	-> there we can create an object(entity of jpa) and persist in db
	-> controller can directly pick the latest state of acocung directly form jpa(its own D.B structure that can be flezible as per need)
	-> also we can get list of exvents based on id of account/aggregate object -> useful in case of data courruption
	
	

Axon have 2 queues -> one for ocmmand -> command app will publiush from controlelr to this and directly bypass data poersistence
	-> axon will call the @commandhandlker annotaed method of aggregate grom there we can call event source and publish to axon event que
	-> Query app  will be looking for these events source using @eventsourcehandler annotated methods and will save in DB, -> we can use axon api to get data and save in jpa
	-> Controler will still pick data from jpa repo
	-> we cna also query for all the events based on id fo the event -> useful in case of data corruption

Docker command to run axon server:
docker run -d --name axonserver -p 8024:8024 -p 8124:8124 axoniq/axonserver